---
title: 'MCP Fundamentals'
description: 'Understand the Model Context Protocol architecture, primitives, and configuration for Claude Code'
order: 1
duration: '30 minutes'
---

# MCP Fundamentals

The Model Context Protocol (MCP) is an open standard that defines how AI applications connect to external data sources and tools. Released by Anthropic in November 2024 and donated to the Agentic AI Foundation (Linux Foundation) in December 2025, MCP has become the industry-standard protocol for giving language models access to the real world.

**MCP is like USB-C for AI** — a single, universal connector that replaces dozens of bespoke integrations. But it is more than a plug-and-play metaphor. MCP is a full client-server protocol built on JSON-RPC 2.0, with lifecycle management, capability negotiation, and typed primitives.

<Callout type="tip" title="The Core Insight">
Before MCP, every AI tool integration was a custom one-off. MCP replaces all of that with one protocol that any AI application can speak and any tool can implement. Build an MCP server once, and it works with Claude Code, Claude Desktop, VS Code, Cursor, ChatGPT, and every other MCP-compatible client.
</Callout>

---

## The Host-Client-Server Architecture

MCP uses a three-layer architecture. This is not a simple "client talks to server" model — there is an important intermediary.

<Diagram title="MCP Architecture" type="flowchart" caption="Host creates isolated clients for each server">
{`flowchart TB
    subgraph host["MCP Host (Claude Code)"]
        LLM["Language Model"]
        C1["MCP Client 1"]
        C2["MCP Client 2"]
        C3["MCP Client 3"]
    end

    S1["Filesystem Server\nstdio transport"]
    S2["Database Server\nstdio transport"]
    S3["Sentry Server\nHTTP transport"]

    LLM -.->|"uses tools"| C1
    LLM -.->|"uses tools"| C2
    LLM -.->|"uses tools"| C3
    C1 ---|"dedicated\nconnection"| S1
    C2 ---|"dedicated\nconnection"| S2
    C3 ---|"dedicated\nconnection"| S3
`}
</Diagram>

<InfoTable
  columns={[
    { key: 'component', header: 'Component' },
    { key: 'role', header: 'Role' },
    { key: 'examples', header: 'Examples' },
  ]}
  rows={[
    { component: 'Host', role: 'The AI application that coordinates everything. Creates MCP clients, manages connections, and mediates access between the LLM and servers.', examples: 'Claude Code, Claude Desktop, VS Code, Cursor' },
    { component: 'Client', role: 'A connector within the host. Each client maintains a dedicated, isolated connection to exactly one MCP server.', examples: 'Internal objects managed by the host (you do not interact with clients directly)' },
    { component: 'Server', role: 'A program that provides capabilities. Exposes tools, resources, and prompts over the MCP protocol.', examples: 'Filesystem server, PostgreSQL server, GitHub server, custom servers you build' },
  ]}
/>

**Why three layers?** The host acts as a security and coordination layer. It ensures each server connection is isolated (a compromised filesystem server cannot access your database server), that user consent is obtained before tool invocations, and that capability negotiation happens cleanly.

---

## Transport Mechanisms

The transport layer defines *how* JSON-RPC messages travel between client and server.

<InfoTable
  columns={[
    { key: 'transport', header: 'Transport' },
    { key: 'how', header: 'How It Works' },
    { key: 'when', header: 'When to Use' },
  ]}
  rows={[
    { transport: 'stdio', how: 'Host launches server as a subprocess. Messages flow through stdin/stdout.', when: 'Local tools: filesystem, databases, custom scripts. Zero network overhead.' },
    { transport: 'Streamable HTTP', how: 'Server runs as an HTTP service. Client sends POST requests; server can stream via SSE.', when: 'Remote/cloud services: GitHub, Sentry, Notion. Supports OAuth authentication.' },
  ]}
/>

<Diagram title="Transport Comparison" type="flowchart">
{`flowchart LR
    subgraph stdio["stdio (Local)"]
        direction LR
        H1["Host"] -->|"launches subprocess"| S1["Server"]
        H1 -->|"stdin"| S1
        S1 -->|"stdout"| H1
    end

    subgraph http["Streamable HTTP (Remote)"]
        direction LR
        H2["Host"] -->|"HTTP POST"| S2["Server"]
        S2 -->|"Response / SSE"| H2
    end
`}
</Diagram>

<Callout type="warning" title="SSE Transport is Deprecated">
Older docs reference a standalone SSE transport. This has been deprecated in favor of Streamable HTTP. Use `--transport http` for remote servers.
</Callout>

---

## Why MCP Matters

### The Problem It Solves

Before MCP, connecting an AI to external data required custom glue code for every integration — an N-times-M problem:

<Diagram title="Before and After MCP" type="flowchart">
{`flowchart TB
    subgraph before["Before: N x M Integrations"]
        direction TB
        A1["Claude"] ---|"custom"| D1["GitHub"]
        A1 ---|"custom"| D2["Slack"]
        A2["ChatGPT"] ---|"custom"| D1
        A2 ---|"custom"| D2
    end

    subgraph after["After: N + M via MCP"]
        direction TB
        B1["Claude"]
        B2["ChatGPT"]
        MCP["MCP Protocol"]
        E1["GitHub Server"]
        E2["Slack Server"]
        B1 --- MCP
        B2 --- MCP
        MCP --- E1
        MCP --- E2
    end
`}
</Diagram>

### Industry Adoption

<InfoTable
  columns={[
    { key: 'milestone', header: 'Milestone' },
    { key: 'date', header: 'Date' },
  ]}
  rows={[
    { milestone: 'Anthropic releases MCP as open source', date: 'November 2024' },
    { milestone: 'OpenAI adopts MCP for ChatGPT Desktop and Agents SDK', date: 'March 2025' },
    { milestone: 'Google DeepMind confirms MCP support for Gemini', date: 'April 2025' },
    { milestone: 'Streamable HTTP transport replaces SSE', date: 'Spec 2025-03-26' },
    { milestone: 'Anthropic donates MCP to Agentic AI Foundation (Linux Foundation)', date: 'December 2025' },
    { milestone: '97M+ monthly SDK downloads, 10,000+ active servers', date: 'Late 2025' },
  ]}
/>

### What This Means for You

MCP gives Claude Code:

- **Real-time data access** — Query production databases, check Sentry errors, pull from GitHub, without copy-pasting
- **Automation loops** — Chain actions: "Find the bug in Sentry, create a GitHub issue, draft a fix, open a PR"
- **Context persistence** — MCP connections maintain state across your session
- **Cross-tool composability** — Combine any set of servers into a full development environment

---

## The Three MCP Primitives

MCP servers expose three types of capabilities, each with a different control model.

<Diagram title="MCP Primitives" type="flowchart">
{`flowchart TB
    subgraph tools["Tools (Model-Controlled)"]
        T1["AI model decides\nwhen to call them"]
        T2["Examples: query DB,\ncreate file, call API"]
    end

    subgraph resources["Resources (Application-Controlled)"]
        R1["Host application decides\nhow to use them"]
        R2["Examples: file contents,\nDB schemas, API docs"]
    end

    subgraph prompts["Prompts (User-Controlled)"]
        P1["User explicitly\nselects them"]
        P2["Examples: code review\ntemplate, commit generator"]
    end

    User["User"] -->|"selects"| prompts
    App["Host App"] -->|"manages"| resources
    Model["Language Model"] -->|"invokes"| tools
`}
</Diagram>

### Tools (Model-Controlled)

**Tools** are executable functions that Claude can invoke to perform actions. The model decides whether and when to call them based on conversation context.

Think of tools as the "hands" of the AI — they let it *do things*.

```json
{
  "name": "query_database",
  "description": "Execute a read-only SQL query against the analytics database",
  "inputSchema": {
    "type": "object",
    "properties": {
      "query": {
        "type": "string",
        "description": "SQL query to execute (SELECT only)"
      }
    },
    "required": ["query"]
  }
}
```

### Resources (Application-Controlled)

**Resources** are data sources that provide context. Unlike tools, they are not actions — they are *information*. The host decides how to incorporate resource data.

Think of resources as the "eyes" of the AI — they let it *see things* it could not otherwise access.

Each resource has a unique URI (e.g., `file:///project/schema.sql`, `git://repo/main`) and can support subscriptions for real-time updates.

### Prompts (User-Controlled)

**Prompts** are pre-defined message templates that users explicitly select. They are the most "human-in-the-loop" primitive.

Think of prompts as "recipes" — structured workflows that a server author packages for common tasks. In Claude Code, they are accessible via `/mcp__servername__promptname` commands.

### Summary: Who Controls What

<InfoTable
  columns={[
    { key: 'primitive', header: 'Primitive' },
    { key: 'controlled', header: 'Controlled By' },
    { key: 'used', header: 'Invoked Via' },
  ]}
  rows={[
    { primitive: 'Tools', controlled: 'The AI model', used: 'tools/call (model decides automatically)' },
    { primitive: 'Resources', controlled: 'The host application', used: 'resources/read (app decides)' },
    { primitive: 'Prompts', controlled: 'The user', used: 'prompts/get (user selects explicitly)' },
  ]}
/>

---

## Configuring MCP in Claude Code

### Adding Servers with the CLI

```bash
# Add a remote HTTP server
claude mcp add --transport http github https://api.githubcopilot.com/mcp/

# Add a remote server with auth header
claude mcp add --transport http sentry https://mcp.sentry.dev/mcp \
  --header "Authorization: Bearer your-token"

# Add a local stdio server
claude mcp add postgres -- npx -y @modelcontextprotocol/server-postgres \
  "postgresql://user:pass@localhost/mydb"

# Add with explicit scope
claude mcp add --transport http notion --scope project https://mcp.notion.com/mcp
```

<Callout type="warning" title="Flag Ordering">
All flags (`--transport`, `--env`, `--scope`, `--header`) must come **before** the server name. The `--` separates flags from the command arguments passed to stdio servers.
</Callout>

### Management Commands

```bash
claude mcp list              # List all configured servers
claude mcp get github        # Get details for a specific server
claude mcp remove github     # Remove a server
claude mcp restart           # Restart all MCP servers
/mcp                         # Check status inside Claude Code
```

### The Three Configuration Scopes

<InfoTable
  columns={[
    { key: 'scope', header: 'Scope' },
    { key: 'flag', header: 'CLI Flag' },
    { key: 'stored', header: 'Stored In' },
    { key: 'use', header: 'Best For' },
  ]}
  rows={[
    { scope: 'Local', flag: '--scope local (default)', stored: '~/.claude.json (under project path)', use: 'Personal dev servers, experiments' },
    { scope: 'Project', flag: '--scope project', stored: '.mcp.json in project root', use: 'Team-shared servers (commit to git)' },
    { scope: 'User', flag: '--scope user', stored: '~/.claude.json (global section)', use: 'Personal utilities across all projects' },
  ]}
/>

**Precedence**: Local wins over project, which wins over user.

<Callout type="tip" title="Sharing with Your Team">
Use `--scope project` to write configurations to `.mcp.json` at your project root. Commit this file so everyone gets the same MCP tools. Claude Code prompts each user for approval before using project-scoped servers.
</Callout>

### Configuration File Format

**`.mcp.json` (Project scope):**

```json
{
  "mcpServers": {
    "github": {
      "type": "http",
      "url": "https://api.githubcopilot.com/mcp/"
    },
    "postgres": {
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-postgres"],
      "env": {
        "DATABASE_URL": "${DATABASE_URL:-postgresql://localhost/mydb}"
      }
    }
  }
}
```

### Environment Variable Expansion

The `.mcp.json` file supports environment variable expansion:

- `${VAR}` — expands to the value of `VAR`
- `${VAR:-default}` — uses `default` if `VAR` is not set

This works in `command`, `args`, `env`, `url`, and `headers` fields. Essential for sharing configs without hardcoding secrets.

---

## The Complete Lifecycle

Here is what happens when you ask Claude a question that requires external data:

<Diagram title="MCP Lifecycle" type="flowchart">
{`flowchart TB
    A["You ask:\n'Check Sentry for auth errors'"] --> B["Claude Code connects\nto configured servers"]
    B --> C["Tool Discovery\n(tools/list)"]
    C --> D["Claude sees tools,\ndecides to call\nsentry.list_issues"]
    D --> E["MCP Client sends\ntools/call request"]
    E --> F["Sentry Server\nexecutes query"]
    F --> G["Claude processes\nresults and responds"]
`}
</Diagram>

1. **You ask a question** that requires external data
2. **Claude Code** has already connected to your configured MCP servers
3. **Claude** sees available tools and decides which to call
4. **The MCP client** sends the request through the appropriate connection
5. **The MCP server** executes the action and returns results
6. **Claude** receives results and formulates a response

All of this happens automatically. You just ask in natural language.

<Callout type="tip" title="Check Status Anytime">
Type `/mcp` inside Claude Code to see all connected servers, their status, available tools, and authentication state. This is the quickest way to debug connection issues.
</Callout>

---

## Next Steps

Now that you understand MCP fundamentals:

1. [Essential MCP Servers →](./essential-servers) — Install the top 10 servers
2. [Building Custom MCPs →](./building-custom-mcps) — Create your own
3. [Workflows & Troubleshooting →](./workflows-and-troubleshooting) — Real-world patterns

---

<Callout type="success" title="You Now Understand MCP!">
MCP turns Claude from an assistant that only sees what you show it into an integrated development partner with direct access to your tools and data. The rest of this track is about putting that power to practical use.
</Callout>
